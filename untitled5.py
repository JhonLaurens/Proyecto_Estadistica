# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mq_ENdLsRas2Ab3Tjz1n8eMnWcrf7w5T
"""

# PASO 1: Configuración e importación de librerías
# Nota: Instalar paquetes necesarios antes de ejecutar este script usando:
# pip install pandas matplotlib seaborn wordcloud Pillow

print("Verificando librerías necesarias...")

import pandas as pd
import io
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS
from collections import Counter
import re
import numpy as np
import os
import tkinter as tk
from tkinter import filedialog

# Para entornos de Jupyter en VS Code se puede usar IPython.display
try:
    from IPython.display import display, Markdown, HTML
    in_notebook = True
except ImportError:
    in_notebook = False
    # Funciones de fallback para entornos no-Jupyter
    def display(content):
        if hasattr(content, "_repr_html_"):
            print("HTML contenido disponible (se vería en un notebook)")
        else:
            print(content)
            
    class Markdown:
        def __init__(self, text):
            self.text = text
        
        def _repr_markdown_(self):
            return self.text

# Para interactuar con una IA (ejemplo con OpenAI)
# import openai # Descomentar si se usa la API de OpenAI

# --- CONFIGURACIÓN DE API KEY (¡IMPORTANTE!) ---
# Usar variables de entorno en lugar de userdata de Colab
# import os
# OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
# openai.api_key = OPENAI_API_KEY

display(Markdown("## Configuración Inicial y Librerías Importadas"))
print("Listo.")

#-------------------------------------------------------------------------------
# PASO 2: Carga de los datos del archivo CSV
#-------------------------------------------------------------------------------
display(Markdown("---"))
display(Markdown("## PASO 2: Carga del Archivo CSV"))

df = pd.DataFrame() # Inicializar df como DataFrame vacío
nombre_archivo = "No especificado"

print("Por favor, selecciona tu archivo CSV:")
root = tk.Tk()
root.withdraw()
file_path = filedialog.askopenfilename(filetypes=[("CSV files", "*.csv")])

if file_path:
    nombre_archivo = os.path.basename(file_path)
    display(Markdown(f"**Archivo '{nombre_archivo}' seleccionado exitosamente.**"))
    try:
        df = pd.read_csv(file_path, sep=';', decimal=',', encoding='utf-8-sig', low_memory=False)
        display(Markdown("**DataFrame cargado exitosamente desde el archivo seleccionado.**"))
    except UnicodeDecodeError:
        display(Markdown("*Error de decodificación con utf-8-sig. Intentando con latin1...*"))
        try:
            df = pd.read_csv(file_path, sep=';', decimal=',', encoding='latin1', low_memory=False)
            display(Markdown("**DataFrame cargado exitosamente con encoding latin1.**"))
        except Exception as e_latin1:
            display(Markdown(f"<p style='color:red;'>Error al cargar el CSV con latin1: {e_latin1}</p>"))
    except Exception as e_gen:
        display(Markdown(f"<p style='color:red;'>Error general al cargar el CSV: {e_gen}</p>"))
else:
    display(Markdown("<p style='color:orange;'>No se seleccionó ningún archivo. El análisis no puede continuar sin datos.</p>"))


if not df.empty:
    display(Markdown("---"))
    display(Markdown("### Vista Previa de los Datos Cargados"))
    display(HTML(df.head().to_html(classes="table table-striped table-hover", max_rows=5))) # Muestra como tabla HTML bonita
    print(f"Número total de filas: {len(df)}, Número total de columnas: {len(df.columns)}")

    #---------------------------------------------------------------------------
    # PASO 3: Limpieza, Conversión y Preparación de Datos
    #---------------------------------------------------------------------------
    display(Markdown("---"))
    display(Markdown("## PASO 3: Limpieza, Conversión y Preparación de Datos"))
    df_procesado = df.copy()

    # Conversión de fechas
    columnas_fecha = ['FECHA_ENCUESTA', 'FECHA_VINCULACION', 'FECHA_NACIMIENTO_FUNDACION']
    for col in columnas_fecha:
        if col in df_procesado.columns:
            try:
                df_procesado[col] = pd.to_datetime(df_procesado[col], format='%d/%m/%Y', errors='coerce')
            except Exception as e_fecha:
                print(f"Advertencia: Problema al convertir la columna de fecha '{col}': {e_fecha}. Algunos valores podrían ser NaT.")
                df_procesado[col] = pd.to_datetime(df_procesado[col], errors='coerce')
        else:
            print(f"Advertencia: Columna de fecha '{col}' no encontrada en el DataFrame.")
    print("-> Columnas de fecha procesadas.")

    # Conversión de preguntas numéricas y estrato
    columnas_preguntas_num = ['PREGUNTA_1', 'PREGUNTA_2', 'PREGUNTA_3', 'PREGUNTA_4']
    for col in columnas_preguntas_num:
        if col in df_procesado.columns:
            df_procesado[col] = pd.to_numeric(df_procesado[col], errors='coerce')
        else:
            print(f"Advertencia: Columna de pregunta numérica '{col}' no encontrada.")

    if 'ESTRATO' in df_procesado.columns:
        df_procesado['ESTRATO'] = pd.to_numeric(df_procesado['ESTRATO'], errors='coerce').astype('Int64') # Usar Int64 para permitir NAs si los hay
        print("-> Columna ESTRATO convertida a tipo numérico entero (permite nulos).")
    else:
        print("Advertencia: Columna 'ESTRATO' no encontrada.")

    # Cálculo de EDAD y ANTIGUEDAD
    if 'FECHA_ENCUESTA' in df_procesado.columns and df_procesado['FECHA_ENCUESTA'].notna().any():
        fecha_referencia = df_procesado['FECHA_ENCUESTA'].max()
        if pd.isna(fecha_referencia): fecha_referencia = datetime.now() # Fallback si max es NaT
    else:
        fecha_referencia = datetime.now()
        if 'FECHA_ENCUESTA' not in df_procesado.columns:
            print("Advertencia: Columna 'FECHA_ENCUESTA' no encontrada, usando fecha actual como referencia.")
        else:
            print("Advertencia: Columna 'FECHA_ENCUESTA' no contiene fechas válidas, usando fecha actual como referencia.")

    if 'FECHA_NACIMIENTO_FUNDACION' in df_procesado.columns:
        if not pd.api.types.is_datetime64_any_dtype(df_procesado['FECHA_NACIMIENTO_FUNDACION']):
            df_procesado['FECHA_NACIMIENTO_FUNDACION'] = pd.to_datetime(df_procesado['FECHA_NACIMIENTO_FUNDACION'], errors='coerce')
        valid_dates_mask = df_procesado['FECHA_NACIMIENTO_FUNDACION'].notna()
        df_procesado.loc[valid_dates_mask, 'EDAD'] = ((fecha_referencia - df_procesado.loc[valid_dates_mask, 'FECHA_NACIMIENTO_FUNDACION']).dt.days / 365.25)
        df_procesado['EDAD'] = df_procesado['EDAD'].astype(float).round(0).fillna(-1).astype(int)
        print("-> Columna EDAD calculada.")
    else:
        df_procesado['EDAD'] = -1
        print("Advertencia: Columna FECHA_NACIMIENTO_FUNDACION no encontrada. Columna EDAD creada con valor -1.")

    if 'FECHA_VINCULACION' in df_procesado.columns:
        if not pd.api.types.is_datetime64_any_dtype(df_procesado['FECHA_VINCULACION']):
            df_procesado['FECHA_VINCULACION'] = pd.to_datetime(df_procesado['FECHA_VINCULACION'], errors='coerce')
        valid_dates_mask_v = df_procesado['FECHA_VINCULACION'].notna()
        df_procesado.loc[valid_dates_mask_v, 'ANTIGUEDAD_CLIENTE_ANOS'] = ((fecha_referencia - df_procesado.loc[valid_dates_mask_v, 'FECHA_VINCULACION']).dt.days / 365.25)
        df_procesado['ANTIGUEDAD_CLIENTE_ANOS'] = df_procesado['ANTIGUEDAD_CLIENTE_ANOS'].astype(float).round(1).fillna(-1.0)
        print("-> Columna ANTIGUEDAD_CLIENTE_ANOS calculada.")
    else:
        df_procesado['ANTIGUEDAD_CLIENTE_ANOS'] = -1.0
        print("Advertencia: Columna FECHA_VINCULACION no encontrada. Columna ANTIGUEDAD_CLIENTE_ANOS creada con valor -1.0.")

    # Limpieza profesional de PREGUNTA_5 (comentarios)
    if 'PREGUNTA_5' in df_procesado.columns:
        df_procesado['PREGUNTA_5_ORIGINAL'] = df_procesado['PREGUNTA_5']
        df_procesado['PREGUNTA_5_LIMPIA'] = df_procesado['PREGUNTA_5'].astype(str).str.lower().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
        df_procesado['PREGUNTA_5_LIMPIA'] = df_procesado['PREGUNTA_5_LIMPIA'].apply(lambda x: re.sub(r'[^\w\s]|(?<!\w)\d+(?!\w)', '', x))
        df_procesado['PREGUNTA_5_LIMPIA'] = df_procesado['PREGUNTA_5_LIMPIA'].apply(lambda x: re.sub(r'\s+', ' ', x).strip())
        patrones_no_informativos = [
            r"^\s*buena\s*s*$", r"^\s*no\s*$", r"^\s*ninguna\s*s*$", r"^\s*ok\s*$",
            r"^\s*excelente\s*s*$", r"^\s*todo\s*bien\s*$", r"^\s*no\s*ninguno\s*$",
            r"^\s*ninguno\s*s*$", r"^\s*no\s*la\s*tengo\s*$", r"^\s*todo\s*perfecto\s*$",
            r"^\s*no\s*por\s*ahora\s*$", r"^\s*cordial\s*saludo\s*$",
            r"^\s*gracias\s*$", r"^\s*bien\s*$", r"^\s*no\s*aplica\s*$", r"^\s*nada\s*$",
            r"^\s*todo\s*muy\s*\w*\s*$", r"^\s*sigan\s*asi\s*$",
            r"^\s*estoy\s*satisfecho\s*con\s*el\s*servicio\s*$",
            r"^\s*felicitaciones\s*$", r"^\s*ningunas\s*y\s*$",
            r"^\s*no\s*ninguno\s*hace\s*muchos\s*anos\s*q\s*soy\s*clienta\s*$"
        ]
        for patron in patrones_no_informativos:
            df_procesado['PREGUNTA_5_LIMPIA'] = df_procesado['PREGUNTA_5_LIMPIA'].replace(to_replace=patron, value=pd.NA, regex=True)
        df_procesado['PREGUNTA_5_LIMPIA'] = df_procesado['PREGUNTA_5_LIMPIA'].replace(r'^\s*$', pd.NA, regex=True)
        print(f"-> Columna PREGUNTA_5_LIMPIA procesada. Comentarios significativos restantes: {df_procesado['PREGUNTA_5_LIMPIA'].count()} de {len(df_procesado)}")
    else:
        print("Advertencia: Columna PREGUNTA_5 no encontrada.")

    display(Markdown("---"))
    display(Markdown("### Información del DataFrame Después del Procesamiento"))
    # df_procesado.info() # Esta salida puede ser muy larga, opcionalmente mostrarla resumida
    info_buffer_display = io.StringIO()
    df_procesado.info(buf=info_buffer_display)
    display(Markdown(f"```\n{info_buffer_display.getvalue()}\n```"))


    display(Markdown("### Primeras Filas del DataFrame Transformado"))
    display(HTML(df_procesado.head().to_html(classes="table table-striped table-hover", max_rows=5)))

    columnas_numericas_descriptivas = [col for col in columnas_preguntas_num + ['ESTRATO', 'EDAD', 'ANTIGUEDAD_CLIENTE_ANOS'] if col in df_procesado.columns and pd.api.types.is_numeric_dtype(df_procesado[col])]
    if columnas_numericas_descriptivas:
        display(Markdown("### Estadísticas Descriptivas de Columnas Numéricas Clave"))
        display(HTML(df_procesado[columnas_numericas_descriptivas].describe().round(2).to_html(classes="table table-striped table-hover")))
    else:
        print("No hay columnas numéricas para mostrar estadísticas descriptivas.")

    #---------------------------------------------------------------------------
    # PASO 4: Análisis Exploratorio de Datos (EDA) Profesional (Python)
    #---------------------------------------------------------------------------
    display(Markdown("---"))
    display(Markdown("## PASO 4: Análisis Exploratorio de Datos (EDA)"))
    sns.set_theme(style="whitegrid", palette="pastel") # Estilo de gráficos mejorado

    # 1. Puntuación de Satisfacción General (Promedio P1-P4)
    if all(col in df_procesado.columns for col in columnas_preguntas_num):
        df_procesado['SATISFACCION_GENERAL'] = df_procesado[columnas_preguntas_num].mean(axis=1)
        display(Markdown("### 4.1. Distribución de la Satisfacción General"))
        plt.figure(figsize=(10, 6))
        sns.histplot(df_procesado['SATISFACCION_GENERAL'].dropna(), kde=True, bins=15, color="skyblue")
        plt.title('Distribución de Puntuación de Satisfacción General (Promedio P1-P4)', fontsize=15)
        plt.xlabel('Puntuación Promedio de Satisfacción (Escala 1-5)', fontsize=12)
        plt.ylabel('Frecuencia', fontsize=12)
        plt.axvline(df_procesado['SATISFACCION_GENERAL'].mean(), color='red', linestyle='dashed', linewidth=1.5, label=f"Media: {df_procesado['SATISFACCION_GENERAL'].mean():.2f}")
        plt.axvline(df_procesado['SATISFACCION_GENERAL'].median(), color='green', linestyle='dashed', linewidth=1.5, label=f"Mediana: {df_procesado['SATISFACCION_GENERAL'].median():.2f}")
        plt.legend()
        plt.show()
        print(f"Satisfacción General Promedio Global: {df_procesado['SATISFACCION_GENERAL'].mean():.2f}")
        print(f"Mediana de Satisfacción General Global: {df_procesado['SATISFACCION_GENERAL'].median():.2f}")
        print(f"Desviación Estándar de Satisfacción General: {df_procesado['SATISFACCION_GENERAL'].std():.2f}")

        display(Markdown("### 4.2. Calificación Promedio por Pregunta Específica"))
        mean_scores = df_procesado[columnas_preguntas_num].mean().sort_values(ascending=False)
        plt.figure(figsize=(10, 6))
        bars = sns.barplot(x=mean_scores.index, y=mean_scores.values, palette="viridis")
        for bar in bars.patches:
            bars.annotate(format(bar.get_height(), '.2f'),
                           (bar.get_x() + bar.get_width() / 2,
                            bar.get_height()), ha='center', va='center',
                           size=10, xytext=(0, 8),
                           textcoords='offset points')
        plt.title('Calificación Promedio por Pregunta de Satisfacción', fontsize=15)
        plt.ylabel('Calificación Promedio (Escala 1-5)', fontsize=12)
        plt.xlabel('Pregunta Específica', fontsize=12)
        plt.ylim(0, 5.5)
        plt.show()
        display(Markdown("**Interpretación Preliminar:**"))
        print(f"La pregunta con mayor calificación promedio es '{mean_scores.index[0]}' ({mean_scores.iloc[0]:.2f}), "
              f"mientras que la de menor calificación es '{mean_scores.index[-1]}' ({mean_scores.iloc[-1]:.2f}).")

    else:
        print("Advertencia: No todas las columnas de preguntas numéricas están presentes. No se puede calcular SATISFACCION_GENERAL o comparar medias.")

    # 3. Satisfacción por Segmentos Demográficos Clave
    display(Markdown("### 4.3. Análisis de Satisfacción por Segmentos Demográficos"))
    segmentos_analisis = ['ESTRATO', 'GENERO', 'CIUDAD_AGENCIA']
    if 'SATISFACCION_GENERAL' in df_procesado.columns:
        for seg in segmentos_analisis:
            if seg in df_procesado.columns:
                plt.figure(figsize=(12, 7) if seg == 'CIUDAD_AGENCIA' else (10,6)) # Ajustar tamaño

                # Para CIUDAD_AGENCIA, mostrar solo las N más frecuentes
                if seg == 'CIUDAD_AGENCIA' and df_procesado[seg].nunique() > 7:
                    top_n_grupos = df_procesado[seg].value_counts().nlargest(7).index
                    data_filtrada_seg = df_procesado[df_procesado[seg].isin(top_n_grupos)]
                    orden_seg = top_n_grupos
                    titulo_seg = f'Satisfacción General por {seg} (Top 7)'
                else:
                    data_filtrada_seg = df_procesado
                    orden_seg = data_filtrada_seg[seg].value_counts().index # Ordenar por frecuencia
                    titulo_seg = f'Satisfacción General por {seg}'

                sns.boxplot(data=data_filtrada_seg, x=seg, y='SATISFACCION_GENERAL', order=orden_seg, palette="Set2")
                plt.title(titulo_seg, fontsize=15)
                plt.xlabel(seg, fontsize=12)
                plt.ylabel('Puntuación de Satisfacción General', fontsize=12)
                plt.xticks(rotation=45, ha='right' if df_procesado[seg].nunique() > 4 else 'center')
                plt.tight_layout()
                plt.show()

                display(Markdown(f"**Satisfacción General Promedio por {seg}:**"))
                if not data_filtrada_seg.empty:
                    satisfaccion_por_seg = data_filtrada_seg.groupby(seg)['SATISFACCION_GENERAL'].agg(['mean', 'count', 'std']).round(2).sort_values(by='mean', ascending=False)
                    display(HTML(satisfaccion_por_seg.to_html(classes="table table-striped table-hover")))
                else:
                    print(f"No hay datos suficientes para agrupar por {seg}.")
    else:
        print("Advertencia: 'SATISFACCION_GENERAL' no calculada, no se puede analizar por segmentos.")

    # 4. Correlación entre variables numéricas
    display(Markdown("### 4.4. Matriz de Correlación"))
    columnas_corr = columnas_preguntas_num + ['ESTRATO', 'EDAD', 'ANTIGUEDAD_CLIENTE_ANOS', 'SATISFACCION_GENERAL']
    columnas_corr_existentes = [col for col in columnas_corr if col in df_procesado.columns and pd.api.types.is_numeric_dtype(df_procesado[col])]
    if len(columnas_corr_existentes) > 1:
        corr_matrix = df_procesado[columnas_corr_existentes].corr()
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5, vmin=-1, vmax=1)
        plt.title('Matriz de Correlación entre Variables Numéricas Clave', fontsize=15)
        plt.show()
        # display(HTML(corr_matrix.round(2).to_html(classes="table table-striped table-hover")))
        print("Las correlaciones entre las preguntas de satisfacción (P1-P4) y la 'SATISFACCION_GENERAL' son, como se espera, altas y positivas. "
              "La correlación entre EDAD y SATISFACCION_GENERAL es débilmente positiva, sugiriendo una ligera tendencia a mayor satisfacción con mayor edad. "
              "ESTRATO y ANTIGUEDAD_CLIENTE_ANOS muestran correlaciones muy débiles con la satisfacción general.")
    else:
        print("No hay suficientes columnas numéricas para generar una matriz de correlación.")

    # 5. Análisis de Texto (PREGUNTA_5_LIMPIA) - Nube de Palabras y Frecuencias
    display(Markdown("### 4.5. Análisis de Comentarios Abiertos (PREGUNTA_5)"))
    word_counts = Counter()
    if 'PREGUNTA_5_LIMPIA' in df_procesado.columns and df_procesado['PREGUNTA_5_LIMPIA'].count() > 0:
        texto_comentarios = " ".join(str(comentario) for comentario in df_procesado['PREGUNTA_5_LIMPIA'].dropna())
        stopwords_es = set(STOPWORDS)
        # Lista más refinada de stopwords
        stopwords_es.update([
            'q', 'mas', 'un', 'una', 'unos', 'unas', 'al', 'del', 'lo', 'la', 'el', 'los', 'las', 'de', 'en', 'y', 'e', 'o', 'u',
            'para', 'por', 'con', 'sin', 'sobre', 'mi', 'me', 'se', 'le', 'les', 'su', 'sus', 'nos', 'como', 'pero', 'si', 'no',
            'muy', 'mucho', 'poco', 'todo', 'toda', 'todos', 'todas', 'tambien', 'asi', 'hacer', 'hacen', 'hace', 'ser', 'es', 'son',
            'sea', 'sean', 'fue', 'era', 'estar', 'esta', 'estan', 'estoy', 'estaba', 'tener', 'tiene', 'tienen', 'tenia',
            'gracias', 'favor', 'poder', 'cliente', 'clientes', 'cdt', 'cdts', 'entidad', 'banco', 'financiera', 'coltefinanciera',
            'oficina', 'servicio', 'atencion', 'asesor', 'dinero', 'cuenta', 'pago', 'pagos', 'interes', 'intereses', 'bueno', 'buenos',
            'bien', 'mejor', 'momento', 'satisfecho', 'satisfecha', 'favor', 'sugerencia', 'sugiero', 'gustaria', 'creo', 'parece',
            'quisiera', 'deberian', 'deberia', 'ustedes', 'ahora', 'dia', 'dias', 'vez', 'veces', 'parte', 'caso', 'tema', 'cosa', 'cosas',
            'solo', 'sino', 'tal', 'ver', 'manera', 'forma', 'tipo', 'ejemplo', 'saber', 'decir', 'ir', 'dar', 'ver', 'pues', 'ante',
            'siempre', 'tan', 'cual', 'cuales', 'xq', 'sr', 'sra', 'dr', 'dra'
        ])

        wordcloud = WordCloud(width=1200, height=600, background_color='white', stopwords=stopwords_es, collocations=False, min_font_size=10, prefer_horizontal=0.9).generate(texto_comentarios)
        plt.figure(figsize=(14, 7))
        plt.imshow(wordcloud, interpolation="bilinear")
        plt.axis("off")
        plt.title('Nube de Palabras de Comentarios Significativos (PREGUNTA_5_LIMPIA)', fontsize=15)
        plt.show()

        palabras_tokenizadas = [palabra for comentario in df_procesado['PREGUNTA_5_LIMPIA'].dropna() for palabra in str(comentario).split() if palabra not in stopwords_es and len(palabra) > 2 and palabra.isalpha()]
        word_counts = Counter(palabras_tokenizadas)
        if word_counts:
            display(Markdown("**Palabras más frecuentes en comentarios (PREGUNTA_5_LIMPIA):**"))
            # Convertir a DataFrame para mostrar como tabla HTML
            df_word_counts = pd.DataFrame(word_counts.most_common(20), columns=['Palabra', 'Frecuencia'])
            display(HTML(df_word_counts.to_html(classes="table table-striped table-hover", index=False)))
        else:
            print("No se encontraron palabras frecuentes significativas en los comentarios después del filtrado.")
    else:
        print("No hay comentarios significativos en PREGUNTA_5_LIMPIA para analizar.")

    #---------------------------------------------------------------------------
    # PASO 5: Preparar Resumen de Datos para la IA
    #---------------------------------------------------------------------------
    display(Markdown("---"))
    display(Markdown("## PASO 5: Preparación del Resumen de Datos para la IA"))

    info_buffer_ia = io.StringIO()
    df_procesado.info(buf=info_buffer_ia)
    df_info_str_ia = info_buffer_ia.getvalue()

    cols_describe_ia = [col for col in columnas_preguntas_num + ['ESTRATO', 'EDAD', 'ANTIGUEDAD_CLIENTE_ANOS', 'SATISFACCION_GENERAL'] if col in df_procesado.columns and pd.api.types.is_numeric_dtype(df_procesado[col])]
    df_describe_str_ia = df_procesado[cols_describe_ia].describe().round(2).to_string() if cols_describe_ia else "No hay columnas numéricas relevantes para describir."

    column_names_str_ia = ", ".join(df_procesado.columns.tolist())
    # Para la IA, es mejor enviar el df.head() como string formateado que como CSV si el prompt se va a leer
    df_sample_str_ia = df_procesado.head(3).to_string() # Muestra pequeña, 3 filas, como string

    resumen_satisfaccion_estrato = ""
    if 'ESTRATO' in df_procesado.columns and 'SATISFACCION_GENERAL' in df_procesado.columns and not df_procesado.empty:
        resumen_satisfaccion_estrato = df_procesado.groupby('ESTRATO')['SATISFACCION_GENERAL'].agg(['mean', 'count', 'std']).round(2).sort_values(by='mean', ascending=False).to_string()

    # Corrección del f-string para la satisfacción general
    satisfaccion_general_mean_str = f"{df_procesado['SATISFACCION_GENERAL'].mean():.2f}" if 'SATISFACCION_GENERAL' in df_procesado.columns else 'N/A'

    data_summary_for_ia = f"""
    RESUMEN DEL CONJUNTO DE DATOS DE LA ENCUESTA DE SATISFACCIÓN (Archivo: {nombre_archivo}):

    Nombres de todas las columnas en el DataFrame procesado:
    {column_names_str_ia}

    Información general del DataFrame procesado (tipos de datos, nulos):
    ```
    {df_info_str_ia}
    ```

    Estadísticas descriptivas para columnas numéricas clave:
    ```
    {df_describe_str_ia}
    ```

    Primeras 3 filas de los datos procesados:
    ```
    {df_sample_str_ia}
    ```

    Distribución de Género (%):
    {df_procesado['GENERO'].value_counts(normalize=True).mul(100).round(1).to_string() if 'GENERO' in df_procesado.columns and not df_procesado['GENERO'].empty else 'N/A'}

    Distribución de Segmento (%):
    {df_procesado['SEGMENTO'].value_counts(normalize=True).mul(100).round(1).to_string() if 'SEGMENTO' in df_procesado.columns and not df_procesado['SEGMENTO'].empty else 'N/A'}
    (Nota: En esta muestra, el segmento parece ser predominantemente '{df_procesado['SEGMENTO'].mode()[0] if 'SEGMENTO' in df_procesado.columns and not df_procesado['SEGMENTO'].empty else "No determinado"}').

    Distribución de Estrato (%):
    {df_procesado['ESTRATO'].value_counts(normalize=True).mul(100).round(1).sort_index().to_string() if 'ESTRATO' in df_procesado.columns and not df_procesado['ESTRATO'].empty else 'N/A'}

    Top 5 Ciudades de Residencia con conteos:
    {df_procesado['CIUDAD_RESIDENCIA'].value_counts().nlargest(5).to_string() if 'CIUDAD_RESIDENCIA' in df_procesado.columns and not df_procesado['CIUDAD_RESIDENCIA'].empty else 'N/A'}

    Satisfacción General Promedio Global (escala 1-5, basado en P1-P4): {satisfaccion_general_mean_str}
    Satisfacción General Promedio por Estrato (media, conteo, desviación estándar):
    ```
    {resumen_satisfaccion_estrato if resumen_satisfaccion_estrato else 'N/A'}
    ```

    Calificaciones promedio para preguntas individuales de satisfacción:
    ```
    {mean_scores.round(2).to_string() if 'mean_scores' in locals() else 'N/A'}
    ```

    Palabras clave más frecuentes en comentarios abiertos (PREGUNTA_5_LIMPIA), después de filtrar palabras comunes (si se generaron):
    {', '.join([f'{palabra} ({cuenta})' for palabra, cuenta in word_counts.most_common(15)]) if word_counts else 'No se generaron palabras frecuentes o no hay comentarios significativos.'}
    Número de comentarios significativos en PREGUNTA_5_LIMPIA: {df_procesado['PREGUNTA_5_LIMPIA'].count() if "PREGUNTA_5_LIMPIA" in df_procesado.columns else 0} de {len(df_procesado)} encuestas ({ (df_procesado['PREGUNTA_5_LIMPIA'].count() / len(df_procesado) * 100) if "PREGUNTA_5_LIMPIA" in df_procesado.columns and len(df_procesado) > 0 else 0 :.1f}%).
    """
    print("-> Resumen de datos para la IA generado.")

    #---------------------------------------------------------------------------
    # PASO 6: Prompt Mejorado para la IA (en Español)
    #---------------------------------------------------------------------------
    display(Markdown("---"))
    display(Markdown("## PASO 6: Prompt Detallado para la IA (en Español)"))

    # El nombre del archivo se toma de la variable 'nombre_archivo' definida durante la carga
    prompt_para_ia_es = f"""
    Actúa como un analista de datos senior experto en encuestas de satisfacción de clientes para una entidad financiera en Colombia.
    He cargado y preprocesado datos de una encuesta llamada '{nombre_archivo if 'nombre_archivo' in locals() else "Encuesta de Satisfacción"}', que contiene {len(df_procesado)} respuestas.
    Te proporciono un resumen detallado de estos datos, incluyendo estadísticas descriptivas, distribuciones y hallazgos preliminares del análisis exploratorio.

    **RESUMEN DE DATOS PROPORCIONADO (BASE PARA TU ANÁLISIS):**
    {data_summary_for_ia}

    **TAREA:**
    Basándote EXCLUSIVAMENTE en el resumen de datos proporcionado, genera un informe de análisis de datos exploratorio en ESPAÑOL y en formato Markdown. El informe debe ser estructurado, profesional, con un tono formal y ofrecer insights accionables para la entidad financiera. Sé detallado en tu interpretación.

    **ESTRUCTURA DEL INFORME (formato Markdown, en ESPAÑOL):**

    # Informe de Análisis Exploratorio: Encuesta de Satisfacción de Clientes ({nombre_archivo if 'nombre_archivo' in locals() else "Encuesta de Satisfacción"})

    ## 1. Introducción y Contexto General del Conjunto de Datos
        *   Describe brevemente el propósito probable de la encuesta (ej. medir la satisfacción con diversos aspectos de la entidad y recopilar feedback).
        *   Menciona el número total de respuestas ({len(df_procesado)}) y variables (columnas) en el conjunto de datos procesado.
        *   Resume los principales tipos de datos encontrados (categóricos, numéricos, fechas, texto).
        *   Indica si se crearon nuevas variables de utilidad para el análisis (ej. EDAD, ANTIGUEDAD_CLIENTE_ANOS, SATISFACCION_GENERAL) y su propósito.

    ## 2. Perfil Demográfico y de Vinculación de los Encuestados
        *   **Género:** Analiza la distribución porcentual y cualquier implicación o sesgo notable.
        *   **Segmento:** Describe la composición del segmento. Si es homogéneo (ej. solo 'Personas'), coméntalo y su implicación para la generalización.
        *   **Estrato Socioeconómico:** Detalla la distribución porcentual. ¿Hay concentración en algún estrato? ¿Cómo podría esto influir en las percepciones o necesidades?
        *   **Edad:** Describe el rango de edad, la edad promedio y la mediana (si están disponibles). ¿Hay grupos de edad predominantes? ¿Podría esto relacionarse con la antigüedad o tipo de servicio usado?
        *   **Antigüedad como Cliente (años):** Analiza el rango, promedio y mediana (si disponibles). ¿Predominan clientes nuevos, antiguos o hay una mezcla? ¿Qué podría implicar esto sobre la lealtad o la captación reciente?
        *   **Distribución Geográfica:** Comenta sobre las principales ciudades de residencia (Top 5) y la concentración de encuestados. ¿Hay alguna implicación regional?

    ## 3. Evaluación de la Satisfacción: Preguntas de Calificación (PREGUNTA_1 a PREGUNTA_4)
        *   Asume que estas preguntas miden diferentes facetas de la satisfacción en una escala (ej. 1-5, donde 5 es la máxima satisfacción).
        *   Para cada pregunta individual (PREGUNTA_1, PREGUNTA_2, PREGUNTA_3, PREGUNTA_4):
            *   Interpreta qué aspecto específico podría estar evaluando la pregunta (ej. calidad del producto/servicio, amabilidad del personal, eficiencia de procesos, facilidad de uso de canales, etc.).
            *   Analiza su calificación promedio y la tendencia general (alta, media, baja). Compara con el punto medio de la escala (ej. 3 en una escala de 1-5).
        *   **Comparativa entre Preguntas:** Utiliza la información de "Calificaciones promedio para preguntas individuales". ¿Qué preguntas muestran consistentemente mayor/menor satisfacción? ¿Qué áreas específicas de la entidad parecen ser fortalezas o debilidades según estas calificaciones?
        *   **Índice de Satisfacción General (SATISFACCION_GENERAL):** Comenta sobre el promedio global y la mediana de satisfacción. ¿Indica un nivel general alto, medio o bajo de satisfacción? Considera la desviación estándar para entender la dispersión.

    ## 4. Análisis de la Satisfacción por Segmentos Clave
        *   Utilizando la información de "Satisfacción General Promedio por Estrato" (media, conteo, std):
            *   ¿Existen diferencias notables en la satisfacción promedio entre diferentes estratos? ¿Son estas diferencias estadísticamente significativas o solo tendencias (considera el 'conteo' y 'std')?
            *   Si se proporcionara información similar para otros segmentos (ej. Género, Ciudad de Agencia) en el resumen, analízalos de manera similar.
            *   ¿Qué segmentos parecen estar más o menos satisfechos? ¿Posibles hipótesis o factores subyacentes que podrían explicar estas diferencias?

    ## 5. Análisis Cualitativo: Comentarios de los Clientes (PREGUNTA_5_LIMPIA)
        *   Indica el porcentaje de encuestados que dejaron comentarios significativos. ¿Es una tasa de respuesta adecuada para obtener insights cualitativos?
        *   Basándote en las "Palabras clave más frecuentes" y la muestra de datos proporcionada (si la hay):
            *   Identifica y describe los **temas positivos recurrentes** (elogios, aspectos específicos valorados por los clientes).
            *   Identifica y describe los **temas negativos recurrentes** (quejas, problemas específicos, áreas de frustración).
            *   Identifica y describe las **sugerencias principales** o ideas constructivas propuestas por los clientes.
        *   Intenta categorizar los temas (ej. atención al cliente, procesos, productos, tecnología, instalaciones, etc.).
        *   Si las palabras clave son muy genéricas o los comentarios pocos, reflexiona sobre la limitación de esta parte del análisis y la necesidad de un análisis más profundo.

    ## 6. Calidad de los Datos y Consideraciones Metodológicas
        *   Basado en la sección de `df_info_str_ia` (información del DataFrame), comenta sobre la completitud general de los datos. ¿Hubo columnas con un alto porcentaje de valores nulos después de la limpieza inicial?
        *   ¿Fueron necesarias transformaciones importantes de datos? (ej. fechas, limpieza de texto).
        *   Considera si el tamaño de la muestra ({len(df_procesado)}) y su distribución demográfica (estratos, ciudades) permiten generalizar los hallazgos a toda la base de clientes de la entidad o si se debe ser cauto.

    ## 7. Conclusiones Principales y Hallazgos Accionables
        *   Resume los 3-5 hallazgos más críticos y relevantes del análisis, integrando tanto los datos cuantitativos como los cualitativos.
        *   **Fortalezas Clave Identificadas:** ¿Qué aspectos de la entidad o su servicio son consistentemente bien valorados?
        *   **Áreas Prioritarias de Mejora:** ¿Qué aspectos específicos requieren atención urgente para mejorar la satisfacción del cliente? Sé específico y cita evidencia de los datos.
        *   ¿Hay segmentos de clientes (demográficos o por comportamiento inferido) que necesiten un enfoque diferenciado o estrategias particulares?

    ## 8. Recomendaciones Estratégicas y Próximos Pasos Analíticos
        *   **Recomendaciones para la Entidad:** Basado en los hallazgos, sugiere 2-3 acciones estratégicas concretas y priorizadas que la entidad podría considerar para abordar las áreas de oportunidad y capitalizar las fortalezas.
        *   **Profundización del Análisis:**
            *   ¿Qué otros cruces de variables o segmentaciones no cubiertas en el resumen serían valiosos investigar (ej. satisfacción por antigüedad del cliente, por ejecutivo asignado, por producto principal si se conociera)?
            *   Sugerir la aplicación de técnicas más avanzadas (ej. análisis de sentimiento más formal y detallado para PREGUNTA_5, análisis de correlación con variables operativas si estuvieran disponibles, o incluso modelos predictivos de satisfacción o churn si se contara con datos longitudinales).
            *   ¿Sería útil realizar un seguimiento con encuestas más específicas o focus groups sobre los temas problemáticos identificados para entender mejor las causas raíz?

    **IMPORTANTE (PARA LA IA):**
    *   Mantén un tono profesional, objetivo y analítico.
    *   Tu análisis debe estar completamente fundamentado en el "RESUMEN DE DATOS PROPORCIONADO". No inventes información ni hagas suposiciones más allá de lo que los datos sugieren.
    *   Si alguna información solicitada no se encuentra en el resumen, indícalo claramente (ej., "El resumen no proporciona detalles sobre X, por lo tanto, no se puede analizar este aspecto con la información disponible").
    *   El informe debe estar redactado íntegramente en **ESPAÑOL**.
    *   Utiliza el formato Markdown de manera efectiva para asegurar una excelente legibilidad y presentación profesional del informe.
    """
    display(Markdown(f"```markdown\n{prompt_para_ia_es}\n```")) # Mostrar el prompt en un bloque de código Markdown
    print("-> Prompt detallado para la IA generado.")


    #---------------------------------------------------------------------------
    # PASO 7: (Opcional) Interactuar con la IA para generar el informe
    #---------------------------------------------------------------------------
    display(Markdown("---"))
    display(Markdown("## PASO 7: Generación del Informe con IA (Opcional)"))
    informe_generado_ia_md = "### Informe de IA no generado (API Key no configurada o sección comentada).\nEl análisis Python y la generación del prompt en español sí se ejecutaron."

    # DESCOMENTA LA SIGUIENTE SECCIÓN PARA USAR LA API DE OPENAI (u otra IA)
    """
    if 'OPENAI_API_KEY' in locals() and OPENAI_API_KEY and OPENAI_API_KEY != "TU_API_KEY_DE_OPENAI_AQUI":
        print("\n--- Interactuando con la IA para generar el informe en Español ---")
        try:
            # Ejemplo usando openai, ajusta si usas otra librería/API
            # response = openai.ChatCompletion.create( # API v0
            response = openai.chat.completions.create( # API v1+
                model="gpt-4o", # O "gpt-3.5-turbo-16k", "gpt-4-turbo"
                messages=[
                    {"role": "system", "content": "Eres un analista de datos experto que genera informes detallados y profesionales en español, basados en resúmenes de datos proporcionados."},
                    {"role": "user", "content": prompt_para_ia_es}
                ],
                temperature=0.2,
                max_tokens=4090 # Un poco menos del límite para dar espacio a la respuesta
            )
            informe_generado_ia_md = response.choices[0].message.content
            display(Markdown("**Informe generado por la IA en Español.**"))
        except Exception as e_ia:
            error_message_ia = f"### Error al generar el informe con la IA:\n```\n{e_ia}\n```\n\nAsegúrate de que tu API key es válida, tienes saldo, y la librería `openai` está actualizada (ej. `pip install --upgrade openai`). El prompt en español fue generado y puedes usarlo manualmente."
            display(Markdown(f"<p style='color:red;'>{error_message_ia}</p>"))
            informe_generado_ia_md = error_message_ia # Guardar el error para mostrarlo
    else:
        display(Markdown("<p style='color:orange;'>API Key no configurada. El informe de IA no se generará automáticamente.</p>"))
        print("Puedes copiar el prompt en español (mostrado arriba) y usarlo manualmente en una interfaz de IA.")
    """ # FIN DE LA SECCIÓN A DESCOMENTAR

    #---------------------------------------------------------------------------
    # PASO 8: Mostrar el informe generado por la IA
    #---------------------------------------------------------------------------
    display(Markdown("---"))
    display(Markdown("## PASO 8: Informe Final Generado"))
    display(Markdown(informe_generado_ia_md))

else:
    display(Markdown("<p style='color:red; font-weight:bold;'>El DataFrame está vacío o no se pudo cargar. El análisis no puede continuar.</p>"))